

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="python" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="python" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>arctern_pyspark._wrapper_func &mdash; Arctern 0.2.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> Arctern
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../python_api.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spark_api.html">Spark API</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Arctern</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">Module code</a> &raquo;</li>
        
      <li>arctern_pyspark._wrapper_func</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for arctern_pyspark._wrapper_func</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (C) 2019-2020 Zilliz. All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;ST_Point&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Intersection&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_IsValid&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_PrecisionReduce&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Equals&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Touches&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Overlaps&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Crosses&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_IsSimple&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_GeometryType&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_MakeValid&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_SimplifyPreserveTopology&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_PolygonFromEnvelope&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Contains&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Intersects&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Within&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Distance&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Area&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Centroid&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Length&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_HausdorffDistance&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_ConvexHull&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_NPoints&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Envelope&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Buffer&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Union_Aggr&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Envelope_Aggr&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Transform&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_CurveToLine&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_GeomFromGeoJSON&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_PointFromText&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_PolygonFromText&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_LineStringFromText&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_GeomFromText&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_GeomFromWKT&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_AsText&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Projection&quot;</span><span class="p">,</span>
    <span class="s2">&quot;TransformAndProjection&quot;</span><span class="p">,</span>
    <span class="s2">&quot;WktToWkb&quot;</span><span class="p">,</span>
    <span class="s2">&quot;WkbToWkt&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="kn">import</span> <span class="nn">arctern</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">pandas_udf</span><span class="p">,</span> <span class="n">PandasUDFType</span>

<span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">Projection</span><span class="p">(</span><span class="n">geos</span><span class="p">,</span> <span class="n">bottom_right</span><span class="p">,</span> <span class="n">top_left</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">projection</span><span class="p">(</span><span class="n">geos</span><span class="p">,</span> <span class="n">bottom_right</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">top_left</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">height</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">width</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">TransformAndProjection</span><span class="p">(</span><span class="n">geos</span><span class="p">,</span> <span class="n">src_rs</span><span class="p">,</span> <span class="n">dst_rs</span><span class="p">,</span> <span class="n">bottom_right</span><span class="p">,</span> <span class="n">top_left</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">transform_and_projection</span><span class="p">(</span><span class="n">geos</span><span class="p">,</span> <span class="n">src_rs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dst_rs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">bottom_right</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">top_left</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">height</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">width</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">WktToWkb</span><span class="p">(</span><span class="n">wkts</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">wkt2wkb</span><span class="p">(</span><span class="n">wkts</span><span class="p">)</span>

<span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">WkbToWkt</span><span class="p">(</span><span class="n">wkbs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">wkb2wkt</span><span class="p">(</span><span class="n">wkbs</span><span class="p">)</span>

<div class="viewcode-block" id="ST_PointFromText"><a class="viewcode-back" href="../../api/Spark_ST_PointFromText.html#arctern_pyspark._wrapper_func.ST_PointFromText">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_PointFromText</span><span class="p">(</span><span class="n">geo</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Constructs point objects from the OGC Well-Known text representation.</span>

<span class="sd">    :type geo: pandas.Series.object</span>
<span class="sd">    :param geo: Geometries organized as WKT.</span>

<span class="sd">    :return: Geometries organized as WKB.</span>
<span class="sd">    :rtype: pandas.Series.object</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; spark_session.conf.set(&quot;spark.sql.execution.arrow.pyspark.enabled&quot;, &quot;true&quot;)</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POINT (30 10)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; data_df = spark_session.createDataFrame(data=test_data, schema=[&quot;data&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; data_df.createOrReplaceTempView(&quot;data&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_PointFromText(data)) from data&quot;).show(100,0)</span>
<span class="sd">      +---------------------------------+</span>
<span class="sd">      |ST_AsText(ST_PointFromText(data))|</span>
<span class="sd">      +---------------------------------+</span>
<span class="sd">      |POINT (30 10)                    |</span>
<span class="sd">      +---------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_GeomFromText</span><span class="p">(</span><span class="n">geo</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_PolygonFromText"><a class="viewcode-back" href="../../api/Spark_ST_PolygonFromText.html#arctern_pyspark._wrapper_func.ST_PolygonFromText">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_PolygonFromText</span><span class="p">(</span><span class="n">geo</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Constructs polygon objects from the OGC Well-Known text representation.</span>
<span class="sd">    </span>
<span class="sd">    :type geo: pandas.Series.object</span>
<span class="sd">    :param geo: Geometries organized as WKT.</span>

<span class="sd">    :return: Geometries organized as WKB.</span>
<span class="sd">    :rtype: pandas.Series.object</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; spark_session.conf.set(&quot;spark.sql.execution.arrow.pyspark.enabled&quot;, &quot;true&quot;)</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON ((0 0,0 1,1 1,1 0,0 0))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; data_df = spark_session.createDataFrame(data=test_data, schema=[&quot;data&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; data_df.createOrReplaceTempView(&quot;data&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_PolygonFromText(data)) from data&quot;).show(100,0)</span>
<span class="sd">      +-----------------------------------+</span>
<span class="sd">      |ST_AsText(ST_PolygonFromText(data))|</span>
<span class="sd">      +-----------------------------------+</span>
<span class="sd">      |POLYGON ((0 0,0 1,1 1,1 0,0 0))    |</span>
<span class="sd">      +-----------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>    
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_GeomFromText</span><span class="p">(</span><span class="n">geo</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_LineStringFromText"><a class="viewcode-back" href="../../api/Spark_ST_LineStringFromText.html#arctern_pyspark._wrapper_func.ST_LineStringFromText">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_LineStringFromText</span><span class="p">(</span><span class="n">geo</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Constructs linestring objects from the OGC Well-Known text representation.</span>
<span class="sd">    </span>
<span class="sd">    :type geo: pandas.Series.object</span>
<span class="sd">    :param geo: Geometries organized as WKT.</span>

<span class="sd">    :return: Geometries organized as WKB.</span>
<span class="sd">    :rtype: pandas.Series.object</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; spark_session.conf.set(&quot;spark.sql.execution.arrow.pyspark.enabled&quot;, &quot;true&quot;)</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;LINESTRING (0 0, 0 1, 1 1, 1 0)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; data_df = spark_session.createDataFrame(data=test_data, schema=[&quot;data&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; data_df.createOrReplaceTempView(&quot;data&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_LineStringFromText(data)) from data&quot;).show(100,0)</span>
<span class="sd">      +--------------------------------------+</span>
<span class="sd">      |ST_AsText(ST_LineStringFromText(data))|</span>
<span class="sd">      +--------------------------------------+</span>
<span class="sd">      |LINESTRING (0 0, 0 1, 1 1, 1 0)       |</span>
<span class="sd">      +--------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_GeomFromText</span><span class="p">(</span><span class="n">geo</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_GeomFromWKT"><a class="viewcode-back" href="../../api/Spark_ST_GeomFromWKT.html#arctern_pyspark._wrapper_func.ST_GeomFromWKT">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_GeomFromWKT</span><span class="p">(</span><span class="n">geo</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Constructs geometry objects from the OGC Well-Known text representation.</span>
<span class="sd">    </span>
<span class="sd">    :type geo: pandas.Series.object</span>
<span class="sd">    :param geo: Geometries organized as WKT.</span>

<span class="sd">    :return: Geometries organized as WKB.</span>
<span class="sd">    :rtype: pandas.Series.object</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; spark_session.conf.set(&quot;spark.sql.execution.arrow.pyspark.enabled&quot;, &quot;true&quot;)</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON ((0 0,0 1,1 1,1 0,0 0))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; data_df = spark_session.createDataFrame(data=test_data, schema=[&quot;data&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; data_df.createOrReplaceTempView(&quot;data&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_GeomFromWKT(data)) from data&quot;).show(100,0)</span>
<span class="sd">      +-------------------------------+</span>
<span class="sd">      |ST_AsText(ST_GeomFromWKT(data))|</span>
<span class="sd">      +-------------------------------+</span>
<span class="sd">      |POLYGON ((0 0,0 1,1 1,1 0,0 0))|</span>
<span class="sd">      +-------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_GeomFromText</span><span class="p">(</span><span class="n">geo</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_GeomFromText"><a class="viewcode-back" href="../../api/Spark_ST_GeomFromText.html#arctern_pyspark._wrapper_func.ST_GeomFromText">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_GeomFromText</span><span class="p">(</span><span class="n">geo</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Constructs geometry objects from the OGC Well-Known text representation.</span>
<span class="sd">    </span>
<span class="sd">    :type geo: pandas.Series.object</span>
<span class="sd">    :param geo: Geometries organized as WKT.</span>

<span class="sd">    :return: Geometries organized as WKB.</span>
<span class="sd">    :rtype: pandas.Series.object</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; spark_session.conf.set(&quot;spark.sql.execution.arrow.pyspark.enabled&quot;, &quot;true&quot;)</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON ((0 0,0 1,1 1,1 0,0 0))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; data_df = spark_session.createDataFrame(data=test_data, schema=[&quot;data&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; data_df.createOrReplaceTempView(&quot;data&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_GeomFromText(data)) from data&quot;).show(100,0)</span>
<span class="sd">      +--------------------------------+</span>
<span class="sd">      |ST_AsText(ST_GeomFromText(data))|</span>
<span class="sd">      +--------------------------------+</span>
<span class="sd">      |POLYGON ((0 0,0 1,1 1,1 0,0 0)) |</span>
<span class="sd">      +--------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_GeomFromText</span><span class="p">(</span><span class="n">geo</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_AsText"><a class="viewcode-back" href="../../api/Spark_ST_AsText.html#arctern_pyspark._wrapper_func.ST_AsText">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_AsText</span><span class="p">(</span><span class="n">geo</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the Well-Known Text representation of the geometry.</span>

<span class="sd">    :type geo: pandas.Series.object</span>
<span class="sd">    :param geo: Geometries organized as WKB.</span>
<span class="sd">    </span>
<span class="sd">    :return: Geometries organized as WKT.</span>
<span class="sd">    :rtype: pandas.Series.object </span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; spark_session.conf.set(&quot;spark.sql.execution.arrow.pyspark.enabled&quot;, &quot;true&quot;)</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON ((0 0,0 1,1 1,1 0,0 0))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; data_df = spark_session.createDataFrame(data=test_data, schema=[&quot;data&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; data_df.createOrReplaceTempView(&quot;data&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_GeomFromText(data)) from data&quot;).show(100,0)</span>
<span class="sd">      +--------------------------------+</span>
<span class="sd">      |ST_AsText(ST_GeomFromText(data))|</span>
<span class="sd">      +--------------------------------+</span>
<span class="sd">      |POLYGON ((0 0,0 1,1 1,1 0,0 0)) |</span>
<span class="sd">      +--------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_AsText</span><span class="p">(</span><span class="n">geo</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_Point"><a class="viewcode-back" href="../../api/Spark_ST_Point.html#arctern_pyspark._wrapper_func.ST_Point">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Point</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Construct Point geometries according to the coordinates.</span>

<span class="sd">    :type x: pandas.Series.float64</span>
<span class="sd">    :param x: Abscissa of the point.</span>
<span class="sd">     </span>
<span class="sd">    :type y: pandas.Series.float64</span>
<span class="sd">    :param y: Ordinate of the point.</span>

<span class="sd">    :return: Geometries organized as WKB.</span>
<span class="sd">    :rtype: pandas.Series.object</span>
<span class="sd"> </span>
<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; spark_session.conf.set(&quot;spark.sql.execution.arrow.pyspark.enabled&quot;, &quot;true&quot;)</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; points_data = []</span>
<span class="sd">      &gt;&gt;&gt; points_data.extend([(1,1)])</span>
<span class="sd">      &gt;&gt;&gt; points_df = spark_session.createDataFrame(data=points_data, schema=[&quot;x&quot;, &quot;y&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; points_df.createOrReplaceTempView(&quot;points&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_Point(x, y)) from points&quot;).show(100,0)</span>
<span class="sd">      +-------------------------+</span>
<span class="sd">      |ST_AsText(ST_Point(x, y))|</span>
<span class="sd">      +-------------------------+</span>
<span class="sd">      |POINT (1 1)              |</span>
<span class="sd">      +-------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Point</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_GeomFromGeoJSON"><a class="viewcode-back" href="../../api/Spark_ST_GeomFromGeoJSON.html#arctern_pyspark._wrapper_func.ST_GeomFromGeoJSON">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_GeomFromGeoJSON</span><span class="p">(</span><span class="n">json</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Constructs a geometry object from the GeoJSON representation.</span>

<span class="sd">    :type json: pandas.Series.object</span>
<span class="sd">    :param json: Geometries organized as json</span>
<span class="sd">   </span>
<span class="sd">    :return: Geometries organized as WKB.</span>
<span class="sd">    :rtype: pandas.Series.object</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; spark_session.conf.set(&quot;spark.sql.execution.arrow.pyspark.enabled&quot;, &quot;true&quot;)</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&quot;{\&quot;type\&quot;:\&quot;Point\&quot;,\&quot;coordinates\&quot;:[1,2]}&quot;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&quot;{\&quot;type\&quot;:\&quot;LineString\&quot;,\&quot;coordinates\&quot;:[[1,2],[4,5],[7,8]]}&quot;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&quot;{\&quot;type\&quot;:\&quot;Polygon\&quot;,\&quot;coordinates\&quot;:[[[0,0],[0,1],[1,1],[1,0],[0,0]]]}&quot;,)])</span>
<span class="sd">      &gt;&gt;&gt; json_df = spark_session.createDataFrame(data=test_data, schema=[&quot;json&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; json_df.createOrReplaceTempView(&quot;json&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_GeomFromGeoJSON(json)) from json&quot;).show(100,0)</span>
<span class="sd">      +-----------------------------------+</span>
<span class="sd">      |ST_AsText(ST_GeomFromGeoJSON(json))|</span>
<span class="sd">      +-----------------------------------+</span>
<span class="sd">      |POINT (1 2)                        |</span>
<span class="sd">      +-----------------------------------+</span>
<span class="sd">      |LINESTRING (1 2,4 5,7 8)           |</span>
<span class="sd">      +-----------------------------------+</span>
<span class="sd">      |POLYGON ((0 0,0 1,1 1,1 0,0 0))    |</span>
<span class="sd">      +-----------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_GeomFromGeoJSON</span><span class="p">(</span><span class="n">json</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_Intersection"><a class="viewcode-back" href="../../api/Spark_ST_Intersection.html#arctern_pyspark._wrapper_func.ST_Intersection">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Intersection</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the point set intersection of geometries.</span>
<span class="sd">    </span>
<span class="sd">    For every (left, right) pair with the same offset value in left and right, </span>
<span class="sd">    calculate a geometry that represents their point set intersection.</span>
<span class="sd">    </span>
<span class="sd">    :type left: pandas.Series.object</span>
<span class="sd">    :param left: Geometries organized as WKB.</span>
<span class="sd">     </span>
<span class="sd">    :type right: pandas.Series.object</span>
<span class="sd">    :param right: Geometries organized as WKB.</span>

<span class="sd">    :return: Geometries organized as WKB.</span>
<span class="sd">    :rtype: pandas.Series.object</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; spark_session.conf.set(&quot;spark.sql.execution.arrow.pyspark.enabled&quot;, &quot;true&quot;)</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POINT(0 0)&#39;, &#39;LINESTRING ( 2 0, 0 2 )&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POINT(0 0)&#39;, &#39;LINESTRING ( 0 0, 2 2 )&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; intersection_df = spark_session.createDataFrame(data=test_data, schema=[&quot;left&quot;, &quot;right&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; intersection_df.createOrReplaceTempView(&quot;intersection&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_Intersection(ST_GeomFromText(left), ST_GeomFromText(right))) from intersection&quot;).show(100,0)</span>
<span class="sd">      +-------------------------------------------------------------------------+</span>
<span class="sd">      |ST_AsText(ST_Intersection(ST_GeomFromText(left), ST_GeomFromText(right)))|</span>
<span class="sd">      +-------------------------------------------------------------------------+</span>
<span class="sd">      |GEOMETRYCOLLECTION EMPTY                                                 |</span>
<span class="sd">      +-------------------------------------------------------------------------+</span>
<span class="sd">      |POINT (0 0)                                                              |</span>
<span class="sd">      +-------------------------------------------------------------------------+    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Intersection</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_IsValid"><a class="viewcode-back" href="../../api/Spark_ST_IsValid.html#arctern_pyspark._wrapper_func.ST_IsValid">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;boolean&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_IsValid</span><span class="p">(</span><span class="n">geos</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    For each item in geometries, check if it is of valid geometry format.</span>
<span class="sd">    </span>
<span class="sd">    :type geos: pandas.Series.object</span>
<span class="sd">    :param geos: Geometries organized as WKB.</span>

<span class="sd">    :return: An array of booleans.</span>
<span class="sd">    :rtype: pandas.Series.bool</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; spark_session.conf.set(&quot;spark.sql.execution.arrow.pyspark.enabled&quot;, &quot;true&quot;)</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POINT (30 10)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POINT (30 10)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; valid_df = spark_session.createDataFrame(data=test_data, schema=[&#39;geos&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; valid_df.createOrReplaceTempView(&quot;valid&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_IsValid(ST_GeomFromText(geos)) from valid&quot;).show(100,0)</span>
<span class="sd">      +---------------------------------+</span>
<span class="sd">      |ST_IsValid(ST_GeomFromText(geos))|</span>
<span class="sd">      +---------------------------------+</span>
<span class="sd">      |true                             |</span>
<span class="sd">      +---------------------------------+</span>
<span class="sd">      |true                             |</span>
<span class="sd">      +---------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_IsValid</span><span class="p">(</span><span class="n">geos</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_PrecisionReduce"><a class="viewcode-back" href="../../api/Spark_ST_PrecisionReduce.html#arctern_pyspark._wrapper_func.ST_PrecisionReduce">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_PrecisionReduce</span><span class="p">(</span><span class="n">geos</span><span class="p">,</span> <span class="n">precision</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Reduce the precision of geometry.</span>
<span class="sd">     </span>
<span class="sd">    For every geometry in geometries, reduce the decimal places of its coordinates </span>
<span class="sd">    to the given number. The last decimal place will be rounded. </span>
<span class="sd">   </span>
<span class="sd">    Note, the operation is performed NOT in &quot;inplace&quot; manner, i.e., new geometries </span>
<span class="sd">    in arrow::Array format will be construted and extra memory will be allocated.</span>
<span class="sd">   </span>
<span class="sd">    :type geos: pandas.Series.object</span>
<span class="sd">    :param geos: Geometries organized as WKT.</span>
<span class="sd">   </span>
<span class="sd">    :type precision: uint32</span>
<span class="sd">    :param geos: The number to reduce the decimals places to.</span>
<span class="sd">   </span>
<span class="sd">    :return: Geometries organized as WKB.</span>
<span class="sd">    :rtype: pandas.Series.object</span>
<span class="sd">   </span>
<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POINT (10.777 11.888)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; precision_reduce_df = spark_session.createDataFrame(data=test_data, schema=[&quot;geos&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; precision_reduce_df.createOrReplaceTempView(&quot;precision_reduce&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_PrecisionReduce(ST_GeomFromText(geos), 4)) from precision_reduce&quot;).show(100,0)</span>
<span class="sd">      +-------------------------------------------------------+</span>
<span class="sd">      |ST_AsText(ST_PrecisionReduce(ST_GeomFromText(geos), 4))|</span>
<span class="sd">      +-------------------------------------------------------+</span>
<span class="sd">      |POINT (10.78 11.89)                                    |</span>
<span class="sd">      +-------------------------------------------------------+ </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_PrecisionReduce</span><span class="p">(</span><span class="n">geos</span><span class="p">,</span> <span class="n">precision</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span></div>

<div class="viewcode-block" id="ST_Equals"><a class="viewcode-back" href="../../api/Spark_ST_Equals.html#arctern_pyspark._wrapper_func.ST_Equals">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;boolean&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Equals</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check whether geometries are &quot;spatially equal&quot;.</span>
<span class="sd">   </span>
<span class="sd">    For every (left, right) pair with the same offset value in left and right, check </span>
<span class="sd">    if they are &quot;spatially equal&quot;. &quot;Spatially equal&quot; here means two geometries represent </span>
<span class="sd">    the same geometry structure.</span>
<span class="sd">   </span>
<span class="sd">    :type left: pandas.Series.object</span>
<span class="sd">    :param left: Geometries organized as WKB.</span>
<span class="sd">     </span>
<span class="sd">    :type right: pandas.Series.object</span>
<span class="sd">    :param right: Geometries organized as WKB.</span>
<span class="sd">    </span>
<span class="sd">    :return: An array of booleans.</span>
<span class="sd">    :rtype: pandas.Series.bool</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;LINESTRING(0 0, 10 10)&#39;, &#39;LINESTRING(0 0, 5 5, 10 10)&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;LINESTRING(10 10, 0 0)&#39;, &#39;LINESTRING(0 0, 5 5, 10 10)&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; equals_df = spark_session.createDataFrame(data=test_data, schema=[&quot;left&quot;, &quot;right&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; equals_df.createOrReplaceTempView(&quot;equals&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_Equals(ST_GeomFromText(left), ST_GeomFromText(right)) from equals&quot;).show(100,0)</span>
<span class="sd">      +--------------------------------------------------------+</span>
<span class="sd">      |ST_Equals(ST_GeomFromText(left), ST_GeomFromText(right))|</span>
<span class="sd">      +--------------------------------------------------------+</span>
<span class="sd">      |true                                                    |</span>
<span class="sd">      +--------------------------------------------------------+</span>
<span class="sd">      |true                                                    |</span>
<span class="sd">      +--------------------------------------------------------+      </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Equals</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_Touches"><a class="viewcode-back" href="../../api/Spark_ST_Touches.html#arctern_pyspark._wrapper_func.ST_Touches">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;boolean&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Touches</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check whether geometries &quot;touch&quot;.</span>
<span class="sd">   </span>
<span class="sd">    For every (left, right) pair with the same offset value in left and right, check </span>
<span class="sd">    if they &quot;touch&quot;. &quot;Touch&quot; here means two geometries have common points, and the </span>
<span class="sd">    common points locate only on their boundaries.</span>
<span class="sd">   </span>
<span class="sd">    :type left: pandas.Series.object</span>
<span class="sd">    :param left: Geometries organized as WKB.</span>
<span class="sd">     </span>
<span class="sd">    :type right: pandas.Series.object</span>
<span class="sd">    :param right: Geometries organized as WKB.</span>
<span class="sd">    </span>
<span class="sd">    :return: An array of booleans.</span>
<span class="sd">    :rtype: pandas.Series.bool</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;LINESTRING(0 0, 1 1, 0 2)&#39;, &#39;POINT(1 1)&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;LINESTRING(0 0, 1 1, 0 2)&#39;, &#39;POINT(0 2)&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; touches_df = spark_session.createDataFrame(data=test_data, schema=[&quot;left&quot;, &quot;right&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; touches_df.createOrReplaceTempView(&quot;touches&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_Touches(ST_GeomFromText(left), ST_GeomFromText(right)) from touches&quot;).show(100,0)</span>
<span class="sd">      +---------------------------------------------------------+</span>
<span class="sd">      |ST_Touches(ST_GeomFromText(left), ST_GeomFromText(right))|</span>
<span class="sd">      +---------------------------------------------------------+</span>
<span class="sd">      |false                                                    |</span>
<span class="sd">      +---------------------------------------------------------+</span>
<span class="sd">      |true                                                     |</span>
<span class="sd">      +---------------------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Touches</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_Overlaps"><a class="viewcode-back" href="../../api/Spark_ST_Overlaps.html#arctern_pyspark._wrapper_func.ST_Overlaps">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;boolean&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Overlaps</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check whether geometries &quot;spatially overlap&quot;.</span>
<span class="sd">   </span>
<span class="sd">    For every (left, right) pair with the same offset value in left and right, check </span>
<span class="sd">    if they &quot;spatially overlap&quot;. &quot;Spatially overlap&quot; here means two geometries </span>
<span class="sd">    intersect but one does not completely contain another.</span>
<span class="sd">   </span>
<span class="sd">    :type left: pandas.Series.object</span>
<span class="sd">    :param left: Geometries organized as WKB.</span>
<span class="sd">     </span>
<span class="sd">    :type right: pandas.Series.object</span>
<span class="sd">    :param right: Geometries organized as WKB.</span>
<span class="sd">    </span>
<span class="sd">    :return: An array of booleans.</span>
<span class="sd">    :rtype: pandas.Series.bool</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON((1 1, 4 1, 4 5, 1 5, 1 1))&#39;, &#39;POLYGON((3 2, 6 2, 6 6, 3 6, 3 2))&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POINT(1 0.5)&#39;, &#39;LINESTRING(1 0, 1 1, 3 5)&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; overlaps_df = spark_session.createDataFrame(data=test_data, schema=[&quot;left&quot;, &quot;right&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; overlaps_df.createOrReplaceTempView(&quot;overlaps&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark.sql(&quot;select ST_Overlaps(ST_GeomFromText(left), ST_GeomFromText(right)) from overlaps&quot;).show(100,0)</span>
<span class="sd">      +----------------------------------------------------------+</span>
<span class="sd">      |ST_Overlaps(ST_GeomFromText(left), ST_GeomFromText(right))|</span>
<span class="sd">      +----------------------------------------------------------+</span>
<span class="sd">      |true                                                      |</span>
<span class="sd">      +----------------------------------------------------------+</span>
<span class="sd">      |false                                                     |</span>
<span class="sd">      +----------------------------------------------------------+    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Overlaps</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">)</span></div>


<div class="viewcode-block" id="ST_Crosses"><a class="viewcode-back" href="../../api/Spark_ST_Crosses.html#arctern_pyspark._wrapper_func.ST_Crosses">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;boolean&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Crosses</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check whether geometries &quot;spatially cross&quot;.</span>
<span class="sd">   </span>
<span class="sd">    For every (left, right) pair with the same offset value in left and right, check </span>
<span class="sd">    if they &quot;spatially cross&quot;. &quot;Spatially cross&quot; here means two the geometries have</span>
<span class="sd">    some, but not all interior points in common. The intersection of the interiors of</span>
<span class="sd">    the geometries must not be the empty set and must have a dimensionality less than </span>
<span class="sd">    the maximum dimension of the two input geometries.</span>
<span class="sd">    </span>
<span class="sd">    :type left: pandas.Series.object</span>
<span class="sd">    :param left: Geometries organized as WKB.</span>
<span class="sd">     </span>
<span class="sd">    :type right: pandas.Series.object</span>
<span class="sd">    :param right: Geometries organized as WKB.</span>
<span class="sd">    </span>
<span class="sd">    :return: An array of booleans.</span>
<span class="sd">    :rtype: pandas.Series.bool</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;MULTIPOINT((1 3), (4 1), (4 3))&#39;, &#39;POLYGON((2 2, 5 2, 5 5, 2 5, 2 2))&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON((1 1, 4 1, 4 4, 1 4, 1 1))&#39;, &#39;POLYGON((2 2, 5 2, 5 5, 2 5, 2 2))&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; crosses_df = spark_session.createDataFrame(data=test_data, schema=[&quot;left&quot;, &quot;right&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; crosses_df.createOrReplaceTempView(&quot;crosses&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_Crosses(ST_GeomFromText(left), ST_GeomFromText(right)) from crosses&quot;).show(100,0)</span>
<span class="sd">      +---------------------------------------------------------+</span>
<span class="sd">      |ST_Crosses(ST_GeomFromText(left), ST_GeomFromText(right))|</span>
<span class="sd">      +---------------------------------------------------------+</span>
<span class="sd">      |true                                                     |</span>
<span class="sd">      +---------------------------------------------------------+</span>
<span class="sd">      |false                                                    |</span>
<span class="sd">      +---------------------------------------------------------+ </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Crosses</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_IsSimple"><a class="viewcode-back" href="../../api/Spark_ST_IsSimple.html#arctern_pyspark._wrapper_func.ST_IsSimple">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;boolean&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_IsSimple</span><span class="p">(</span><span class="n">geos</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check whether geometry is &quot;simple&quot;.</span>
<span class="sd">   </span>
<span class="sd">    For every geometry in geometries, check if it is &quot;simple&quot;. &quot;Simple&quot; here means </span>
<span class="sd">    that a geometry has no anomalous geometric points such as self intersection or </span>
<span class="sd">    self tangency.</span>
<span class="sd">   </span>
<span class="sd">    :type geos: pandas.Series.object</span>
<span class="sd">    :param geos: Geometries organized as WKB.</span>
<span class="sd">   </span>
<span class="sd">    :return: An array of booleans.</span>
<span class="sd">    :rtype: pandas.Series.bool</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON((1 2, 3 4, 5 6, 1 2))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;LINESTRING(1 1,2 2,2 3.5,1 3,1 2,2 1)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; simple_df = spark_session.createDataFrame(data=test_data, schema=[&#39;geos&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; simple_df.createOrReplaceTempView(&quot;simple&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_IsSimple(ST_GeomFromText(geos)) from simple&quot;).show(100,0)</span>
<span class="sd">      +----------------------------------+</span>
<span class="sd">      |ST_IsSimple(ST_GeomFromText(geos))|</span>
<span class="sd">      +----------------------------------+</span>
<span class="sd">      |false                             |</span>
<span class="sd">      +----------------------------------+</span>
<span class="sd">      |false                             |</span>
<span class="sd">      +----------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_IsSimple</span><span class="p">(</span><span class="n">geos</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_GeometryType"><a class="viewcode-back" href="../../api/Spark_ST_GeometryType.html#arctern_pyspark._wrapper_func.ST_GeometryType">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_GeometryType</span><span class="p">(</span><span class="n">geos</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    For each geometry in geometries, return a string that indicates is type.</span>
<span class="sd">    </span>
<span class="sd">    :type geos: pandas.Series.object</span>
<span class="sd">    :param geos: Geometries organized as WKB.</span>

<span class="sd">    :return: Geometries organized as WKB.</span>
<span class="sd">    :rtype: pandas.Series.object</span>
<span class="sd">    </span>
<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;LINESTRING(77.29 29.07,77.42 29.26,77.27 29.31,77.29 29.07)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POINT (30 10)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; geometry_type_df = spark_session.createDataFrame(data=test_data, schema=[&#39;geos&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; geometry_type_df.createOrReplaceTempView(&quot;geometry_type&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_GeometryType(ST_GeomFromText(geos)) from geometry_type&quot;).show(100,0)</span>
<span class="sd">      +--------------------------------------+</span>
<span class="sd">      |ST_GeometryType(ST_GeomFromText(geos))|</span>
<span class="sd">      +--------------------------------------+</span>
<span class="sd">      |ST_LINESTRING                         |</span>
<span class="sd">      +--------------------------------------+</span>
<span class="sd">      |POINT                                 |</span>
<span class="sd">      +--------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_GeometryType</span><span class="p">(</span><span class="n">geos</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_MakeValid"><a class="viewcode-back" href="../../api/Spark_ST_MakeValid.html#arctern_pyspark._wrapper_func.ST_MakeValid">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_MakeValid</span><span class="p">(</span><span class="n">geos</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    For every geometry in geometries, create a valid representation of it without </span>
<span class="sd">    losing any of the input vertices. Already-valid geometries won&#39;t have further </span>
<span class="sd">    intervention. This function returns geometries which are validated. Note, new </span>
<span class="sd">    geometries are construted in arrow::Array format, so extra memory will be allocated.</span>
<span class="sd">   </span>
<span class="sd">    :type geos: pandas.Series.object</span>
<span class="sd">    :param geos: Geometries organized as WKB.</span>
<span class="sd">    </span>
<span class="sd">    :return: Geometries organized as WKB.</span>
<span class="sd">    :rtype: pandas.Series.object</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;LINESTRING(0 0, 10 0, 20 0, 20 0, 30 0)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON((1 5, 1 1, 3 3, 5 3, 7 1, 7 5, 5 3, 3 3, 1 5))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; make_valid_df = spark_session.createDataFrame(data=test_data, schema=[&#39;geos&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; make_valid_df.createOrReplaceTempView(&quot;make_valid&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_MakeValid(ST_GeomFromText(geos))) from make_valid&quot;).show(100,0)</span>
<span class="sd">      +------------------------------------------------------------------------------------------------+</span>
<span class="sd">      |ST_AsText(ST_MakeValid(ST_GeomFromText(geos)))                                                  |</span>
<span class="sd">      +------------------------------------------------------------------------------------------------+</span>
<span class="sd">      |LINESTRING (0 0,10 0,20 0,20 0,30 0)                                                            |</span>
<span class="sd">      +------------------------------------------------------------------------------------------------+</span>
<span class="sd">      |GEOMETRYCOLLECTION (MULTIPOLYGON (((3 3,1 1,1 5,3 3)),((5 3,7 5,7 1,5 3))),LINESTRING (3 3,5 3))|</span>
<span class="sd">      +------------------------------------------------------------------------------------------------+    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_MakeValid</span><span class="p">(</span><span class="n">geos</span><span class="p">)</span></div>

<span class="c1"># TODO: ST_SimplifyPreserveTopology</span>
<div class="viewcode-block" id="ST_SimplifyPreserveTopology"><a class="viewcode-back" href="../../api/Spark_ST_SimplifyPreserveTopology.html#arctern_pyspark._wrapper_func.ST_SimplifyPreserveTopology">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_SimplifyPreserveTopology</span><span class="p">(</span><span class="n">geos</span><span class="p">,</span> <span class="n">distance_tolerance</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    For each geometry in geometries create a &quot;simplified&quot; version for it according</span>
<span class="sd">    to the precision that parameter tolerance specifies. </span>
<span class="sd">   </span>
<span class="sd">    Note simplified geometries with be construted in arrow::Array format, so extra </span>
<span class="sd">    memory will be allocated.</span>
<span class="sd">   </span>
<span class="sd">    :type geos: pandas.Series.object</span>
<span class="sd">    :param geos: Geometries organized as WKB.</span>
<span class="sd">   </span>
<span class="sd">    :type distance_tolerance: double</span>
<span class="sd">    :param distance_tolerance: The precision of the simplified geometry.</span>
<span class="sd">   </span>
<span class="sd">    :return: Geometries organized as WKB.</span>
<span class="sd">    :rtype: pandas.Series.object </span>
<span class="sd">    </span>
<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(</span>
<span class="sd">          &#39;POLYGON((8 25, 28 22, 28 20, 15 11, 33 3, 56 30, 46 33, 46 34, 47 44, 35 36, 45 33, 43 19, 29 21, 29 22, 35 26, 24 39, 8 25))&#39;,</span>
<span class="sd">          )])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(</span>
<span class="sd">          &#39;LINESTRING(250 250, 280 290, 300 230, 340 300, 360 260, 440 310, 470 360, 604 286)&#39;,</span>
<span class="sd">          )])</span>
<span class="sd">      &gt;&gt;&gt; simplify_preserve_topology_df = spark_session.createDataFrame(data=test_data, schema=[&#39;geos&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; simplify_preserve_topology_df.createOrReplaceTempView(&quot;simplify_preserve_topology&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_SimplifyPreserveTopology(ST_GeomFromText(geos), 10)) from simplify_preserve_topology&quot;).show(100,0)  </span>
<span class="sd">      +----------------------------------------------------------------------------+</span>
<span class="sd">      |ST_AsText(ST_SimplifyPreserveTopology(ST_GeomFromText(geos), 10))           |</span>
<span class="sd">      +----------------------------------------------------------------------------+</span>
<span class="sd">      |POLYGON ((8 25,28 22,15 11,33 3,56 30,47 44,35 36,43 19,24 39,8 25))        |</span>
<span class="sd">      +----------------------------------------------------------------------------+</span>
<span class="sd">      |LINESTRING (250 250,280 290,300 230,340 300,360 260,440 310,470 360,604 286)|</span>
<span class="sd">      +----------------------------------------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_SimplifyPreserveTopology</span><span class="p">(</span><span class="n">geos</span><span class="p">,</span> <span class="n">distance_tolerance</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span></div>

<div class="viewcode-block" id="ST_PolygonFromEnvelope"><a class="viewcode-back" href="../../api/Spark_ST_PolygonFromEnvelope.html#arctern_pyspark._wrapper_func.ST_PolygonFromEnvelope">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_PolygonFromEnvelope</span><span class="p">(</span><span class="n">min_x</span><span class="p">,</span> <span class="n">min_y</span><span class="p">,</span> <span class="n">max_x</span><span class="p">,</span> <span class="n">max_y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Construct polygon(rectangle) geometries from arr_min_x, arr_min_y, arr_max_x, </span>
<span class="sd">    arr_max_y. The edges of polygon are parallel to coordinate axis.</span>
<span class="sd">   </span>
<span class="sd">    :type min_x: pandas.Series.float64</span>
<span class="sd">    :param min_x: The x axis coordinates of the lower left vertical of the rectangles.</span>
<span class="sd">    </span>
<span class="sd">    :type min_y: pandas.Series.float64</span>
<span class="sd">    :param min_y: The y axis coordinates of the lower left vertical of the rectangles.</span>
<span class="sd">    </span>
<span class="sd">    :type max_x: pandas.Series.float64</span>
<span class="sd">    :param max_x: The x axis coordinates of the upper right vertical of the rectangles.</span>
<span class="sd">    </span>
<span class="sd">    :type max_y: pandas.Series.float64</span>
<span class="sd">    :param max_y: The y axis coordinates of the upper right vertical of the rectangles.</span>
<span class="sd">    </span>
<span class="sd">    :return: Geometries organized as WKB.</span>
<span class="sd">    :rtype: pandas.Series.object</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(1.0, 3.0, 5.0, 7.0)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(2.0, 4.0, 6.0, 8.0)])</span>
<span class="sd">      &gt;&gt;&gt; polygon_from_envelope_df = spark_session.createDataFrame(data=test_data, schema=[&#39;min_x&#39;, &#39;min_y&#39;, &#39;max_x&#39;, &#39;max_y&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; polygon_from_envelope_df.createOrReplaceTempView(&#39;polygon_from_envelope&#39;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_PolygonFromEnvelope(min_x, min_y, max_x, max_y)) from polygon_from_envelope&quot;).show(100,0)</span>
<span class="sd">      +-------------------------------------------------------------+</span>
<span class="sd">      |ST_AsText(ST_PolygonFromEnvelope(min_x, min_y, max_x, max_y))|</span>
<span class="sd">      +-------------------------------------------------------------+</span>
<span class="sd">      |POLYGON ((1 3,1 7,5 7,5 3,1 3))                              |</span>
<span class="sd">      +-------------------------------------------------------------+</span>
<span class="sd">      |POLYGON ((2 4,2 8,6 8,6 4,2 4))                              |</span>
<span class="sd">      +-------------------------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_PolygonFromEnvelope</span><span class="p">(</span><span class="n">min_x</span><span class="p">,</span> <span class="n">min_y</span><span class="p">,</span> <span class="n">max_x</span><span class="p">,</span> <span class="n">max_y</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_Contains"><a class="viewcode-back" href="../../api/Spark_ST_Contains.html#arctern_pyspark._wrapper_func.ST_Contains">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;boolean&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Contains</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check whether a geometry contain another geometry.</span>
<span class="sd">   </span>
<span class="sd">    For every (left, right) pair with the same offset value in left and right, check </span>
<span class="sd">    if left_geometry &quot;contains&quot; right_geometry. Left &quot;contains&quot; right means no points</span>
<span class="sd">    of right_geometry lie in the exterior of left_geometry and at least one point of </span>
<span class="sd">    the interior of right_geometry lies in the interior of left_geometry.</span>
<span class="sd">   </span>
<span class="sd">    :type left: pandas.Series.object</span>
<span class="sd">    :param left: Geometries organized as WKB.</span>
<span class="sd">     </span>
<span class="sd">    :type right: pandas.Series.object</span>
<span class="sd">    :param right: Geometries organized as WKB.</span>
<span class="sd">    </span>
<span class="sd">    :return: An array of booleans.</span>
<span class="sd">    :rtype: pandas.Series.bool</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON((-1 3,2 1,0 -3,-1 3))&#39;,&#39;POLYGON((0 2,1 1,0 -1,0 2))&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON((0 2,1 1,0 -1,0 2))&#39;,&#39;POLYGON((-1 3,2 1,0 -3,-1 3))&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; contains_df = spark_session.createDataFrame(data=test_data, schema=[&quot;left&quot;, &quot;right&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; contains_df.createOrReplaceTempView(&quot;contains&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_Contains(ST_GeomFromText(left), ST_GeomFromText(right)) from contains&quot;).show(100,0)</span>
<span class="sd">      +----------------------------------------------------------+</span>
<span class="sd">      |ST_Contains(ST_GeomFromText(left), ST_GeomFromText(right))|</span>
<span class="sd">      +----------------------------------------------------------+</span>
<span class="sd">      |true                                                      |</span>
<span class="sd">      +----------------------------------------------------------+</span>
<span class="sd">      |false                                                     |</span>
<span class="sd">      +----------------------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Contains</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_Intersects"><a class="viewcode-back" href="../../api/Spark_ST_Intersects.html#arctern_pyspark._wrapper_func.ST_Intersects">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;boolean&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Intersects</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check whether two geometries intersect.</span>

<span class="sd">    For every (left, right) pair with the same offset value in left and right, check </span>
<span class="sd">    if left and right shares any portion of space.</span>

<span class="sd">    :type left: pandas.Series.object</span>
<span class="sd">    :param left: Geometries organized as WKB.</span>
<span class="sd">     </span>
<span class="sd">    :type right: pandas.Series.object</span>
<span class="sd">    :param right: Geometries organized as WKB.</span>
<span class="sd">    </span>
<span class="sd">    :return: An array of booleans.</span>
<span class="sd">    :rtype: pandas.Series.bool</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POINT(0 0)&#39;, &#39;LINESTRING ( 0 0, 0 2 )&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POINT(0 0)&#39;,&#39;LINESTRING ( 2 0, 0 2 )&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; intersects_df = spark_session.createDataFrame(data=test_data, schema=[&quot;left&quot;, &quot;right&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; intersects_df.createOrReplaceTempView(&quot;intersects&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_Intersects(ST_GeomFromText(left), ST_GeomFromText(right)) from intersects&quot;).show(100,0)</span>
<span class="sd">      +------------------------------------------------------------+</span>
<span class="sd">      |ST_Intersects(ST_GeomFromText(left), ST_GeomFromText(right))|</span>
<span class="sd">      +------------------------------------------------------------+</span>
<span class="sd">      |true                                                        |</span>
<span class="sd">      +------------------------------------------------------------+</span>
<span class="sd">      |false                                                       |</span>
<span class="sd">      +------------------------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Intersects</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_Within"><a class="viewcode-back" href="../../api/Spark_ST_Within.html#arctern_pyspark._wrapper_func.ST_Within">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;boolean&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Within</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check whether a geometry is within another geometry.</span>
<span class="sd">   </span>
<span class="sd">    For every (left, right) pair with the same offset value in left and right, check </span>
<span class="sd">    if left is &quot;within&quot; right. Left &quot;within&quot; right means no points of left lie in the </span>
<span class="sd">    exterior of right and at least one point of the interior of left lies in the interior</span>
<span class="sd">    of right.</span>
<span class="sd">   </span>
<span class="sd">    :type left: pandas.Series.object</span>
<span class="sd">    :param left: Geometries organized as WKB.</span>
<span class="sd">     </span>
<span class="sd">    :type right: pandas.Series.object</span>
<span class="sd">    :param right: Geometries organized as WKB.</span>
<span class="sd">    </span>
<span class="sd">    :return: An array of booleans.</span>
<span class="sd">    :rtype: pandas.Series.bool</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON((2 2, 7 2, 7 5, 2 5, 2 2))&#39;,&#39;POLYGON((1 1, 8 1, 8 7, 1 7, 1 1))&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON((0 2, 5 2, 5 5, 0 5, 0 2))&#39;,&#39;POLYGON((1 1, 8 1, 8 7, 1 7, 1 1))&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; within_df = spark_session.createDataFrame(data=test_data, schema=[&quot;left&quot;, &quot;right&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; within_df.createOrReplaceTempView(&quot;within&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_Within(ST_GeomFromText(left), ST_GeomFromText(right)) from within&quot;).show(100,0)</span>
<span class="sd">      +--------------------------------------------------------+</span>
<span class="sd">      |ST_Within(ST_GeomFromText(left), ST_GeomFromText(right))|</span>
<span class="sd">      +--------------------------------------------------------+</span>
<span class="sd">      |true                                                    |</span>
<span class="sd">      +--------------------------------------------------------+</span>
<span class="sd">      |false                                                   |</span>
<span class="sd">      +--------------------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Within</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_Distance"><a class="viewcode-back" href="../../api/Spark_ST_Distance.html#arctern_pyspark._wrapper_func.ST_Distance">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;double&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Distance</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the distance between two geometries.</span>
<span class="sd">   </span>
<span class="sd">    For every (left, right) pair with the same offset value in left and right, </span>
<span class="sd">    calculates the minimum 2D Cartesian (planar) distance between left and right.</span>
<span class="sd">   </span>
<span class="sd">    :type left: pandas.Series.object</span>
<span class="sd">    :param left: Geometries organized as WKB.</span>
<span class="sd">     </span>
<span class="sd">    :type right: pandas.Series.object</span>
<span class="sd">    :param right: Geometries organized as WKB.</span>
<span class="sd">     </span>
<span class="sd">    :return: An array of double.</span>
<span class="sd">    :rtype: pandas.Series.float64</span>
<span class="sd">    </span>
<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession .builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON((-1 -1,2 2,0 1,-1 -1))&#39;,&#39;POLYGON((5 2,7 4,5 5,5 2))&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POINT(31.75 31.25)&#39;,&#39;LINESTRING(32 32,32 35,40.5 35,32 35,32 32)&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; distance_df = spark_session.createDataFrame(data=test_data, schema=[&quot;left&quot;, &quot;right&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; distance_df.createOrReplaceTempView(&quot;distance&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_Distance(ST_GeomFromText(left), ST_GeomFromText(right)) from distance&quot;).show(100,0)</span>
<span class="sd">      +----------------------------------------------------------+</span>
<span class="sd">      |ST_Distance(ST_GeomFromText(left), ST_GeomFromText(right))|</span>
<span class="sd">      +----------------------------------------------------------+</span>
<span class="sd">      |3                                                         |</span>
<span class="sd">      +----------------------------------------------------------+</span>
<span class="sd">      |0.7905694150420949                                        |</span>
<span class="sd">      +----------------------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Distance</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_Area"><a class="viewcode-back" href="../../api/Spark_ST_Area.html#arctern_pyspark._wrapper_func.ST_Area">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;double&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Area</span><span class="p">(</span><span class="n">geos</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the area of geometry.</span>
<span class="sd">   </span>
<span class="sd">    For every geometry in geometries, calculate the 2D Cartesian (planar) area</span>
<span class="sd">    of geometry.</span>
<span class="sd">   </span>
<span class="sd">    :type geos: pandas.Series.object</span>
<span class="sd">    :param geos: Geometries organized as WKB.</span>
<span class="sd">   </span>
<span class="sd">    :return: An array of double.</span>
<span class="sd">    :rtype: pandas.Series.float64</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON((10 20,10 30,20 30,30 10))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON((10 20,10 40,30 40,40 10))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; area_df = spark_session.createDataFrame(data=test_data, schema=[&#39;geos&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; area_df.createOrReplaceTempView(&quot;area&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_Area(ST_GeomFromText(geos)) from area&quot;).show(100,0)</span>
<span class="sd">      +------------------------------+</span>
<span class="sd">      |ST_Area(ST_GeomFromText(geos))|</span>
<span class="sd">      +------------------------------+</span>
<span class="sd">      |200                           |</span>
<span class="sd">      +------------------------------+</span>
<span class="sd">      |600                           |</span>
<span class="sd">      +------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Area</span><span class="p">(</span><span class="n">geos</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_Centroid"><a class="viewcode-back" href="../../api/Spark_ST_Centroid.html#arctern_pyspark._wrapper_func.ST_Centroid">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Centroid</span><span class="p">(</span><span class="n">geos</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the centroid of geometry.</span>
<span class="sd">   </span>
<span class="sd">    For every geometry in geometries, compute the controid point of geometry.</span>
<span class="sd">   </span>
<span class="sd">    :type geos: pandas.Series.object</span>
<span class="sd">    :param geos: Geometries organized as WKB.</span>
<span class="sd">   </span>
<span class="sd">    :return: Geometries organized as WKB.</span>
<span class="sd">    :rtype: pandas.Series.object</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;MULTIPOINT ( -1 0, -1 2, -1 3, -1 4, -1 7, 0 1, 0 3, 1 1, 2 0, 6 0, 7 8, 9 8, 10 6 )&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;CIRCULARSTRING(0 2, -1 1,0 0, 0.5 0, 1 0, 2 1, 1 2, 0.5 2, 0 2)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; centroid_df = spark_session.createDataFrame(data=test_data, schema=[&#39;geos&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; centroid_df.createOrReplaceTempView(&quot;centroid&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_Centroid(ST_GeomFromText(geos))) from centroid&quot;).show(100,0)</span>
<span class="sd">      +---------------------------------------------+</span>
<span class="sd">      |ST_AsText(ST_Centroid(ST_GeomFromText(geos)))|</span>
<span class="sd">      +---------------------------------------------+</span>
<span class="sd">      |POINT (2.30769230769231 3.30769230769231)    |</span>
<span class="sd">      +---------------------------------------------+</span>
<span class="sd">      |POINT (0.5 1.0)                              |</span>
<span class="sd">      +---------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Centroid</span><span class="p">(</span><span class="n">geos</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_Length"><a class="viewcode-back" href="../../api/Spark_ST_Length.html#arctern_pyspark._wrapper_func.ST_Length">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;double&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Length</span><span class="p">(</span><span class="n">geos</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the length of linear geometries.</span>
<span class="sd">   </span>
<span class="sd">    For every geometry in geometries, calculate the length of geometry.</span>
<span class="sd">    </span>
<span class="sd">    :type geos: pandas.Series.object</span>
<span class="sd">    :param geos: Geometries organized as WKB.</span>
<span class="sd">    </span>
<span class="sd">    :return: An array of double.</span>
<span class="sd">    :rtype: pandas.Series.float64</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;LINESTRING(743238 2967416,743238 2967450,743265 2967450, 743265.625 2967416,743238 2967416)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;LINESTRING(-72.1260 42.45, -72.1240 42.45666, -72.123 42.1546)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; length_df = spark_session.createDataFrame(data=test_data, schema=[&#39;geos&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; length_df.createOrReplaceTempView(&quot;length&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_Length(ST_GeomFromText(geos)) from length&quot;).show(100,0)</span>
<span class="sd">      +--------------------------------+</span>
<span class="sd">      |ST_Length(ST_GeomFromText(geos))|</span>
<span class="sd">      +--------------------------------+</span>
<span class="sd">      |122.63074400009504              |</span>
<span class="sd">      +--------------------------------+</span>
<span class="sd">      |0.30901547439030225             |</span>
<span class="sd">      +--------------------------------+  </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Length</span><span class="p">(</span><span class="n">geos</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_HausdorffDistance"><a class="viewcode-back" href="../../api/Spark_ST_HausdorffDistance.html#arctern_pyspark._wrapper_func.ST_HausdorffDistance">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;double&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_HausdorffDistance</span><span class="p">(</span><span class="n">geo1</span><span class="p">,</span> <span class="n">geo2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the Hausdorff distance between two geometries, a measure of how similar</span>
<span class="sd">    or dissimilar 2 geometries are.</span>
<span class="sd">   </span>
<span class="sd">    Implements algorithm for computing a distance metric which can be thought of as </span>
<span class="sd">    the &quot;Discrete Hausdorff Distance&quot;. This is the Hausdorff distance restricted to </span>
<span class="sd">    discrete points for one of the geometries. Wikipedia article on Hausdorff distance </span>
<span class="sd">   </span>
<span class="sd">    Martin Davis note on how Hausdorff Distance calculation was used to prove </span>
<span class="sd">    correctness of the CascadePolygonUnion approach.</span>
<span class="sd">   </span>
<span class="sd">    When densifyFrac is specified, this function performs a segment densification before </span>
<span class="sd">    computing the discrete hausdorff distance. The densifyFrac parameter sets the fraction</span>
<span class="sd">    by which to densify each segment. Each segment will be split into a number of equal-length </span>
<span class="sd">    subsegments, whose fraction of the total length is closest to the given fraction.</span>
<span class="sd">   </span>
<span class="sd">    Units are in the units of the spatial reference system of the geometries.</span>
<span class="sd">   </span>
<span class="sd">    :type geo1: pandas.Series.object</span>
<span class="sd">    :param geo1: Geometries organized as WKB.</span>
<span class="sd">     </span>
<span class="sd">    :type geo2: pandas.Series.object</span>
<span class="sd">    :param geo2: Geometries organized as WKB.</span>
<span class="sd">     </span>
<span class="sd">    :return: An array of double.</span>
<span class="sd">    :rtype: pandas.Series.float64</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&quot;POLYGON((0 0 ,0 1, 1 1, 1 0, 0 0))&quot;, &quot;POLYGON((0 0 ,0 2, 1 1, 1 0, 0 0))&quot;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&quot;POINT(0 0)&quot;, &quot;POINT(0 1)&quot;,)])</span>
<span class="sd">      &gt;&gt;&gt; hausdorff_df = spark_session.createDataFrame(data=test_data, schema=[&quot;geo1&quot;, &quot;geo2&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; hausdorff_df.createOrReplaceTempView(&quot;hausdorff&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_HausdorffDistance(ST_GeomFromText(geo1),ST_GeomFromText(geo2)) from hausdorff&quot;).show(100,0)</span>
<span class="sd">      +-----------------------------------------------------------------+</span>
<span class="sd">      |ST_HausdorffDistance(ST_GeomFromText(geo1),ST_GeomFromText(geo2))|</span>
<span class="sd">      +-----------------------------------------------------------------+</span>
<span class="sd">      |1                                                                |</span>
<span class="sd">      +-----------------------------------------------------------------+</span>
<span class="sd">      |1                                                                |</span>
<span class="sd">      +-----------------------------------------------------------------+    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_HausdorffDistance</span><span class="p">(</span><span class="n">geo1</span><span class="p">,</span> <span class="n">geo2</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_ConvexHull"><a class="viewcode-back" href="../../api/Spark_ST_ConvexHull.html#arctern_pyspark._wrapper_func.ST_ConvexHull">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_ConvexHull</span><span class="p">(</span><span class="n">geos</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the convex hull of geometry.</span>
<span class="sd">   </span>
<span class="sd">    Compute the smallest convex geometry that encloses all geometries for a geometry</span>
<span class="sd">    in geometries.</span>
<span class="sd">   </span>
<span class="sd">    :type geos: pandas.Series.object</span>
<span class="sd">    :param geos: Geometries organized as WKB.</span>
<span class="sd">   </span>
<span class="sd">    :return: Geometries organized as WKB.</span>
<span class="sd">    :rtype: pandas.Series.object</span>
<span class="sd">    </span>
<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;GEOMETRYCOLLECTION(POINT(1 1),POINT(0 0))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;GEOMETRYCOLLECTION(LINESTRING(2.5 3,-2 1.5), POLYGON((0 1,1 3,1 -2,0 1)))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; convexhull_df = spark_session.createDataFrame(data=test_data, schema=[&#39;geos&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; convexhull_df.createOrReplaceTempView(&quot;convexhull&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_convexhull(ST_GeomFromText(geos))) from convexhull&quot;).show(100,0)</span>
<span class="sd">      +-----------------------------------------------+</span>
<span class="sd">      |ST_AsText(ST_convexhull(ST_GeomFromText(geos)))|</span>
<span class="sd">      +-----------------------------------------------+</span>
<span class="sd">      |LINESTRING (1 1,0 0)                           |</span>
<span class="sd">      +-----------------------------------------------+</span>
<span class="sd">      |POLYGON ((1 -2,-2.0 1.5,1 3,2.5 3.0,1 -2))     |</span>
<span class="sd">      +-----------------------------------------------+   </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_ConvexHull</span><span class="p">(</span><span class="n">geos</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_NPoints"><a class="viewcode-back" href="../../api/Spark_ST_NPoints.html#arctern_pyspark._wrapper_func.ST_NPoints">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;int&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_NPoints</span><span class="p">(</span><span class="n">geos</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the points number for every geometry in geometries.</span>
<span class="sd">   </span>
<span class="sd">    :type geos: pandas.Series.object</span>
<span class="sd">    :param geos: Geometries organized as WKB.</span>
<span class="sd">   </span>
<span class="sd">    :return : An array of int64.</span>
<span class="sd">    :rtype : pandas.Series.int64</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;LINESTRING(77.29 29.07,77.42 29.26,77.27 29.31,77.29 29.07)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;LINESTRING(77.29 29.07 1,77.42 29.26 0,77.27 29.31 -1,77.29 29.07 3)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; npoints_df = spark_session.createDataFrame(data=test_data, schema=[&#39;geos&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; npoints_df.createOrReplaceTempView(&quot;npoints&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_NPoints(ST_GeomFromText(geos)) from npoints&quot;).show(100,0)</span>
<span class="sd">      +---------------------------------+</span>
<span class="sd">      |ST_NPoints(ST_GeomFromText(geos))|</span>
<span class="sd">      +---------------------------------+</span>
<span class="sd">      |4                                |</span>
<span class="sd">      +---------------------------------+</span>
<span class="sd">      |4                                |</span>
<span class="sd">      +---------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_NPoints</span><span class="p">(</span><span class="n">geos</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_Envelope"><a class="viewcode-back" href="../../api/Spark_ST_Envelope.html#arctern_pyspark._wrapper_func.ST_Envelope">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Envelope</span><span class="p">(</span><span class="n">geos</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the double-precision minimum bounding box geometry for every geometry in geometries.</span>
<span class="sd">   </span>
<span class="sd">    :type geos: pandas.Series.object</span>
<span class="sd">    :param geos: Geometries organized as WKB.</span>
<span class="sd">   </span>
<span class="sd">    :return: Geometries organized as WKB.</span>
<span class="sd">    :rtype: pandas.Series.object</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;point (10 10)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;linestring (0 0 , 0 10)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;linestring (0 0 , 10 0)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;linestring (0 0 , 10 10)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;polygon ((0 0, 10 0, 10 10, 0 10, 0 0))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;multipoint (0 0, 10 0, 5 5)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;multilinestring ((0 0, 5 5), (6 6, 6 7, 10 10))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;multipolygon (((0 0, 10 0, 10 10, 0 10, 0 0), (11 11, 20 11, 20 20, 20 11, 11 11)))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; envelope_df = spark_session.createDataFrame(data=test_data, schema=[&#39;geos&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; envelope_df.createOrReplaceTempView(&quot;envelope&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_Envelope(ST_GeomFromText(geos))) from envelope&quot;).show(100,0)</span>
<span class="sd">      +---------------------------------------------+</span>
<span class="sd">      |ST_AsText(ST_Envelope(ST_GeomFromText(geos)))|</span>
<span class="sd">      +---------------------------------------------+</span>
<span class="sd">      |POINT (10 10)                                |</span>
<span class="sd">      +---------------------------------------------+</span>
<span class="sd">      |LINESTRING (0 0,0 10)                        |</span>
<span class="sd">      +---------------------------------------------+</span>
<span class="sd">      |LINESTRING (0 0,10 0)                        |</span>
<span class="sd">      +---------------------------------------------+</span>
<span class="sd">      |POLYGON ((0 0,0 10,10 10,10 0,0 0))          |</span>
<span class="sd">      +---------------------------------------------+</span>
<span class="sd">      |POLYGON ((0 0,0 10,10 10,10 0,0 0))          |</span>
<span class="sd">      +---------------------------------------------+</span>
<span class="sd">      |POLYGON ((0 0,0 5,10 5,10 0,0 0))            |</span>
<span class="sd">      +---------------------------------------------+</span>
<span class="sd">      |POLYGON ((0 0,0 10,10 10,10 0,0 0))          |</span>
<span class="sd">      +---------------------------------------------+</span>
<span class="sd">      |POLYGON ((0 0,0 20,20 20,20 0,0 0))          |</span>
<span class="sd">      +---------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Envelope</span><span class="p">(</span><span class="n">geos</span><span class="p">)</span></div>

<span class="c1"># TODO: ST_Buffer, how to polymorphicly define the behaviour of spark udf</span>
<div class="viewcode-block" id="ST_Buffer"><a class="viewcode-back" href="../../api/Spark_ST_Buffer.html#arctern_pyspark._wrapper_func.ST_Buffer">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Buffer</span><span class="p">(</span><span class="n">geos</span><span class="p">,</span> <span class="n">dfDist</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a geometry that represents all points whose distance from this geos is </span>
<span class="sd">    less than or equal to distance.</span>
<span class="sd">    </span>
<span class="sd">    :type geos: pandas.Series.object</span>
<span class="sd">    :param geos: Geometries organized as WKB.</span>
<span class="sd">   </span>
<span class="sd">    :type ofDist: int64</span>
<span class="sd">    :param ofDist: The maximum distance of the returned geometry from the given geometry.</span>
<span class="sd"> </span>
<span class="sd">    :return: Geometries organized as WKB.</span>
<span class="sd">    :rtype: pandas.Series.object</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POINT (0 1)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; buffer_df = spark_session.createDataFrame(data=test_data, schema=[&#39;geos&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; buffer_df.createOrReplaceTempView(&quot;buffer&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_Buffer(ST_GeomFromText(geos), 0)) from buffer&quot;).show(100,0)</span>
<span class="sd">      +----------------------------------------------+</span>
<span class="sd">      |ST_AsText(ST_Buffer(ST_GeomFromText(geos), 0))|</span>
<span class="sd">      +----------------------------------------------+</span>
<span class="sd">      |POLYGON EMPTY                                 |</span>
<span class="sd">      +----------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Buffer</span><span class="p">(</span><span class="n">geos</span><span class="p">,</span> <span class="n">dfDist</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span></div>

<div class="viewcode-block" id="ST_Union_Aggr"><a class="viewcode-back" href="../../api/Spark_ST_Union_Aggr.html#arctern_pyspark._wrapper_func.ST_Union_Aggr">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">GROUPED_AGG</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Union_Aggr</span><span class="p">(</span><span class="n">geos</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function returns a MULTI geometry or NON-MULTI geometry from a set of geometries.</span>
<span class="sd">   </span>
<span class="sd">    :type geos: pandas.Series.object</span>
<span class="sd">    :param geos: Geometries organized as WKB.</span>
<span class="sd">   </span>
<span class="sd">    :return: Geometry organized as WKB.</span>
<span class="sd">    :rtype: pandas.Series.object</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data1 = []</span>
<span class="sd">      &gt;&gt;&gt; test_data1.extend([(&#39;POLYGON ((1 1,1 2,2 2,2 1,1 1))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data1.extend([(&#39;POLYGON ((2 1,3 1,3 2,2 2,2 1))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; union_aggr_df1 = spark_session.createDataFrame(data=test_data1, schema=[&#39;geos&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; union_aggr_df1.createOrReplaceTempView(&quot;union_aggr1&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_Union_Aggr(ST_GeomFromText(geos))) from union_aggr1&quot;).show(100,0)</span>
<span class="sd">      +-----------------------------------------------+</span>
<span class="sd">      |ST_AsText(ST_Union_Aggr(ST_GeomFromText(geos)))|</span>
<span class="sd">      +-----------------------------------------------+</span>
<span class="sd">      |POLYGON ((4 1,4 0,0 0,0 4,4 4,4 2,5 2,5 1,4 1))|</span>
<span class="sd">      +-----------------------------------------------+ </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rst</span> <span class="o">=</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Union_Aggr</span><span class="p">(</span><span class="n">geos</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">rst</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span></div>

<div class="viewcode-block" id="ST_Envelope_Aggr"><a class="viewcode-back" href="../../api/Spark_ST_Envelope_Aggr.html#arctern_pyspark._wrapper_func.ST_Envelope_Aggr">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">GROUPED_AGG</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Envelope_Aggr</span><span class="p">(</span><span class="n">geos</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the double-precision minimum bounding box geometry for every geometry in geometries, </span>
<span class="sd">    then returns a MULTI geometry or NON-MULTI geometry from a set of geometries.</span>
<span class="sd">   </span>
<span class="sd">    :type geos: pandas.Series.object</span>
<span class="sd">    :param geos: Geometries organized as WKB.</span>
<span class="sd">   </span>
<span class="sd">    :return: Geometry organized as WKB.</span>
<span class="sd">    :rtype: pandas.Series.object</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON ((0 0,4 0,4 4,0 4,0 0))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON ((5 1,7 1,7 2,5 2,5 1))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; envelope_aggr_df = spark_session.createDataFrame(data=test_data, schema=[&#39;geos&#39;])</span>
<span class="sd">      &gt;&gt;&gt; envelope_aggr_df.createOrReplaceTempView(&#39;envelope_aggr&#39;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_Envelope_Aggr(ST_GeomFromText(geos))) from envelope_aggr&quot;).show(100,0)</span>
<span class="sd">      +--------------------------------------------------+</span>
<span class="sd">      |ST_AsText(ST_Envelope_Aggr(ST_GeomFromText(geos)))|</span>
<span class="sd">      +--------------------------------------------------+</span>
<span class="sd">      |POLYGON ((0 0,0 4,7 4,7 0,0 0))                   |</span>
<span class="sd">      +--------------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rst</span> <span class="o">=</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Envelope_Aggr</span><span class="p">(</span><span class="n">geos</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">rst</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span></div>

<div class="viewcode-block" id="ST_Transform"><a class="viewcode-back" href="../../api/Spark_ST_Transform.html#arctern_pyspark._wrapper_func.ST_Transform">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Transform</span><span class="p">(</span><span class="n">geos</span><span class="p">,</span> <span class="n">src_rs</span><span class="p">,</span> <span class="n">dst_rs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a new geometry with its coordinates transformed to a different spatial </span>
<span class="sd">    reference system.</span>
<span class="sd">   </span>
<span class="sd">    :type geos: pandas.Series.object</span>
<span class="sd">    :param geos: Geometries organized as WKB.</span>
<span class="sd">   </span>
<span class="sd">    :type src_rs: string</span>
<span class="sd">    :param src_rs: The current srid of geometries.</span>
<span class="sd">   </span>
<span class="sd">    :type dst_rs: string</span>
<span class="sd">    :param dst_rs: The target srid of geometries tranfrom to.</span>
<span class="sd">   </span>
<span class="sd">    :return: Geometries organized as WKB.</span>
<span class="sd">    :rtype: pandas.Series.object</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt;  test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POINT (10 10)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; buffer_df = spark_session.createDataFrame(data=test_data, schema=[&#39;geos&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; buffer_df.createOrReplaceTempView(&quot;buffer&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_Transform(ST_GeomFromText(geos), &#39;epsg:4326&#39;, &#39;epsg:3857&#39;)) from buffer&quot;).show(100,0)</span>
<span class="sd">      +------------------------------------------------------------------------+</span>
<span class="sd">      |ST_AsText(ST_Transform(ST_GeomFromText(geos), &#39;epsg:4326&#39;, &#39;epsg:3857&#39;))|</span>
<span class="sd">      +------------------------------------------------------------------------+</span>
<span class="sd">      |POINT (1113194.90793274 1118889.97485796)                               |</span>
<span class="sd">      +------------------------------------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Transform</span><span class="p">(</span><span class="n">geos</span><span class="p">,</span> <span class="n">src_rs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dst_rs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span></div>

<div class="viewcode-block" id="ST_CurveToLine"><a class="viewcode-back" href="../../api/Spark_ST_CurveToLine.html#arctern_pyspark._wrapper_func.ST_CurveToLine">[docs]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_CurveToLine</span><span class="p">(</span><span class="n">geos</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Converts a CIRCULAR STRING to regular LINESTRING or CURVEPOLYGON to POLYGON or </span>
<span class="sd">    MULTISURFACE to MULTIPOLYGON. Useful for outputting to devices that can&#39;t support </span>
<span class="sd">    CIRCULARSTRING geometry types.</span>
<span class="sd">   </span>
<span class="sd">    :type geos: pandas.Series.object</span>
<span class="sd">    :param geos: Geometries organized as WKB.</span>
<span class="sd">   </span>
<span class="sd">    :return: Geometries organized as WKB.</span>
<span class="sd">    :rtype: pandas.Series.object</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;CURVEPOLYGON(CIRCULARSTRING(0 0, 4 0, 4 4, 0 4, 0 0))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; buffer_df = spark_session.createDataFrame(data=test_data, schema=[&#39;geos&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; buffer_df.createOrReplaceTempView(&quot;buffer&quot;)</span>
<span class="sd">      &gt;&gt;&gt; rs=spark_session.sql(&quot;select ST_AsText(ST_CurveToLine(ST_GeomFromText(geos))) from buffer&quot;).collect()</span>
<span class="sd">      &gt;&gt;&gt; assert str(rs[0][0]).startswith(&quot;POLYGON&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_CurveToLine</span><span class="p">(</span><span class="n">geos</span><span class="p">)</span></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, zilliz
      <span class="lastupdated">
        Last updated on Apr 15, 2020.
      </span>

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>